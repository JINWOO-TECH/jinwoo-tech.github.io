---
layout: post
title:  "(1) Apache Kafka - 기본개념"
categories: data_engineering
tags: Apache_Kafka
description: Apache Kafka - 기본개념
---

<h2>
    <span class = "jjw_h2_style">1. Apache Kafka란? </span>
</h2>
<br>

Apache Kafka는 **분산형 이벤트 스트리밍 플랫폼**으로, 대규모 데이터 스트림을 **실시간**으로 처리하고 관리하기 위해 설계된 오픈 소스 소프트웨어입니다.

* Kafka의 주요 목적
  * 데이터 파이프라인: 다양한 데이터 소스에서 데이터를 수집하고, 이를 여러 소비자에게 전달.
  * 실시간 분석: 스트리밍 데이터를 실시간으로 분석.
  * 이벤트 중심 아키텍처: 비동기적으로 이벤트를 전달.

<br>

<h2>
    <span class = "jjw_h2_style">2. Kafka 용어정리 </span>
</h2>

<br>

![Xixia](/assets/images/dataengineer/20241202kafkabasic1.png)
- `주키퍼(Zookeeper)`: 아파치 프로젝트 애플리케이션으로 카프카의 메타데이터(metadata) 관리 및 브로커의 정상상태 점검(health check) 을 담당 합니다.
- `카프카(Kafka)` 또는 카프카 클러스터(Kafka cluster) : 아파치 프로젝트 애플리케이션으로 여러대의 브로커를 구성한 클러스터를 의미 합니다.
- `브로커(broker)` : 카프카 애플리케이션이 설치된 서버 또는 노드를 의미 합니다.
- `프로듀서(producer`): 카프카로 메세지를 보내는 역할을 하는 클라이언트로 총칭 합니다.
- `컨슈머(consumer)` : 카프카에서 메세지를 꺼내가는 역할을 하는 클라이언트를 총칭 합니다.
- `토픽(topic)` : 카프카는 메시지 피드들을 토픽으로 구분하고, 각 토픽의 이름은 카프카 내에서 고유 합니다.
- `파티션(partition)` : 병렬 처리 및 고성능을 얻기 위해 하나의 토픽을 여러개로 나눈 것을 의미 합니다
- `세그먼트(segment)` : 프로듀서가 전송한 실제 메세지가 브로커의 로컬 디스크에 저장되는 파일을 말합니다.
- `메세지(message)` 또는 `레코드(record)`: 프로듀서가 브로커로 전송하거나 컨슈머가 읽어가는 데이터 조각을 말합니다.

<br>

<h2>
    <span class = "jjw_h2_style">3. Kafka의 순차적 동작 과정 </span>
</h2>

<br>

<h3>3.1 데이터 생성과 전송 (Producer)</h3>
- 어떤 시스템이 데이터를 생성하면, Producer가 이를 Kafka에 전달합니다. <br>
예를 들어, 웹 애플리케이션에서 사용자 클릭 로그를 생성하면, 이 데이터는 Producer를 통해 Kafka로 전송됩니다.

- 데이터를 보낼 때 **토픽(Topic)**이라는 데이터 카테고리를 지정합니다.
- Kafka는 이 데이터를 **파티션(Partition)**이라는 단위로 분산 저장합니다.
  - 파티션은 병렬 처리를 위한 구조로, 메시지 순서를 보장합니다.
  - 특정 파티션에 데이터가 저장될지는 Round Robin 방식 또는 키(Hashing)를 기반으로 결정됩니다.

<h3>3.2 데이터 저장 및 관리 (Broker)</h3>
- 데이터를 받은 Kafka는 Broker(Kafka 서버)라는 컴포넌트에 메시지를 저장합니다.
  - Kafka는 데이터를 디스크에 저장하며, 설정된 보존 기간 동안 삭제하지 않습니다.
  - 하나의 메시지는 여러 브로커에 복제(replication)되어 장애 발생 시에도 데이터를 잃지 않도록 합니다.


<h3>3.3 데이터 소비 (Consumer)</h3>

- Kafka에 저장된 데이터는 필요할 때 Consumer가 가져가서 처리합니다.

  - Consumer는 **컨슈머 그룹(Consumer Group)**을 형성하여 데이터를 병렬로 읽을 수 있습니다.
  - Kafka는 동일한 파티션의 데이터를 한 컨슈머 그룹 내에서 하나의 컨슈머만 읽도록 합니다.
    - 이렇게 하면 데이터 중복 처리를 방지하면서 병렬 처리가 가능합니다.

- 컨슈머는 메시지를 읽을 때, **오프셋(Offset)**을 기반으로 데이터 위치를 추적합니다.
  - 오프셋은 메시지의 고유한 번호로, 컨슈머는 이 값을 저장해 두었다가 이후 처리를 이어나갑니다.
  - 따라서 특정 시점의 데이터를 다시 처리하거나 분석하는 것도 가능합니다.
